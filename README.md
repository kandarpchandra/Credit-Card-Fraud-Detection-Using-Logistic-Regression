Credit Card Fraud Detection using Logistic Regression
This project demonstrates fraud detection on credit card transactions using Logistic Regression in Python. The workflow includes data loading, preprocessing (including concatenating two datasets due to a lack of sufficient fraud samples), model training, and evaluation, all performed in a Jupyter notebook.

Dataset
Concatenation of Two Datasets:
Due to the rarity of fraudulent transactions, two credit card transaction datasets were combined to increase the number of fraud samples. This helps create a more balanced and realistic dataset for training and evaluation.
The resulting dataset contains anonymized features (V1 to V28), transaction Amount, and a target column Class (1: Fraud, 0: Not Fraud).
Why SMOTE Was Not Used
SMOTE (Synthetic Minority Over-sampling Technique) is commonly used to address class imbalance by synthesizing new minority class examples.
In this project, SMOTE was found to be not useful because:
The original dataset is high-dimensional and anonymized, so synthetic samples generated by SMOTE may not represent real-world fraudulent patterns and could introduce noise.
For fraud detection, generating artificial fraud cases can risk overfitting and reduce the modelâ€™s generalizability to real data.
Steps Performed
Import Libraries

numpy, pandas, and scikit-learn modules for data handling and modeling.
Load and Combine Data

Both datasets are loaded using pandas and concatenated to create a single, larger DataFrame with more fraud cases.
Initial Exploration

Display the first few rows, check for null values, and analyze class distribution.
Data Cleaning

Drop the id column as it is not relevant for prediction.
Feature Selection

Features: All columns except Class.
Target: Class.
Train-Test Split

Split the dataset into training and testing sets.
Model Training

Train a Logistic Regression model.
Evaluation

Predict on the test set and compute accuracy.
Requirements
Python 3.x
numpy
pandas
scikit-learn
Jupyter notebook or Google Colab
Install dependencies with:

pip install numpy pandas scikit-learn
Notes
Why Concatenate?
The concatenation of two datasets was necessary due to the limited number of fraud samples, allowing the model to learn more effectively.
The dataset remains highly imbalanced; consider using additional metrics (precision, recall, F1-score) for better evaluation.
Further improvements could include data balancing, feature engineering, or trying advanced algorithms.
